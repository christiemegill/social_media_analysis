import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json

class BlueskyAnalyzer:
    def __init__(self, data_file='bluesky_data.json'):
        """Initialize analyzer with data file"""
        with open(data_file, 'r') as f:
            self.raw_data = json.load(f)
        self.df = pd.DataFrame(self.raw_data)
        self.df['created_at'] = pd.to_datetime(self.df['created_at'])
        
        # Set style for all plots
        plt.style.use('default')  # Changed from 'seaborn' to 'default'
        sns.set_theme()  # This will apply seaborn styling after it's imported
    
    def generate_engagement_analysis(self):
        """Analyze engagement patterns"""
        plt.figure(figsize=(15, 10))
        
        # Plot 1: Engagement by Day of Week
        plt.subplot(2, 2, 1)
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        engagement_by_day = self.df.groupby('day_of_week')[['likes', 'reposts', 'replies']].mean()
        engagement_by_day = engagement_by_day.reindex(day_order)
        engagement_by_day.plot(kind='bar')
        plt.title('Average Engagement by Day of Week')
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        # Plot 2: Engagement by Hour
        plt.subplot(2, 2, 2)
        engagement_by_hour = self.df.groupby('hour_of_day')[['likes', 'reposts', 'replies']].mean()
        engagement_by_hour.plot(kind='line', marker='o')
        plt.title('Average Engagement by Hour of Day')
        plt.xlabel('Hour of Day')
        plt.ylabel('Average Count')
        
        # Plot 3: Media Type Impact
        plt.subplot(2, 2, 3)
        media_engagement = self.df.groupby('media_type')['likes'].mean().sort_values(ascending=False)
        media_engagement.plot(kind='bar')
        plt.title('Average Likes by Media Type')
        plt.xticks(rotation=45)
        
        # Plot 4: Author Comparison
        plt.subplot(2, 2, 4)
        author_engagement = self.df.groupby('author')[['likes', 'reposts', 'replies']].mean()
        author_engagement.plot(kind='bar')
        plt.title('Average Engagement by Author')
        plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.savefig('engagement_analysis.png')
        plt.close()
        
    def analyze_content_patterns(self):
        """Analyze content patterns"""
        plt.figure(figsize=(15, 10))
        
        # Plot 1: Word Count Distribution
        plt.subplot(2, 2, 1)
        sns.histplot(data=self.df, x='word_count', bins=30)
        plt.title('Distribution of Post Lengths')
        plt.xlabel('Word Count')
        
        # Plot 2: Engagement vs Word Count
        plt.subplot(2, 2, 2)
        sns.scatterplot(data=self.df, x='word_count', y='likes')
        plt.title('Engagement vs Post Length')
        plt.xlabel('Word Count')
        plt.ylabel('Likes')
        
        # Plot 3: Media Type Distribution
        plt.subplot(2, 2, 3)
        self.df['media_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')
        plt.title('Distribution of Media Types')
        
        # Plot 4: Time Series of Posts
        plt.subplot(2, 2, 4)
        daily_posts = self.df.resample('D', on='created_at').size()
        daily_posts.plot(kind='line', marker='o')
        plt.title('Posting Frequency Over Time')
        plt.xlabel('Date')
        plt.ylabel('Number of Posts')
        
        plt.tight_layout()
        plt.savefig('content_analysis.png')
        plt.close()
        
    def generate_insights_report(self):
        """Generate key insights from the data"""
        insights = {
            "Post Timing": {
                "Best Day": self.df.groupby('day_of_week')['likes'].mean().idxmax(),
                "Best Hour": int(self.df.groupby('hour_of_day')['likes'].mean().idxmax()),
                "Weekend vs Weekday": {
                    "Weekend Avg Likes": float(self.df[self.df['is_weekend']]['likes'].mean()),
                    "Weekday Avg Likes": float(self.df[~self.df['is_weekend']]['likes'].mean())
                }
            },
            "Content Analysis": {
                "Avg Word Count": float(self.df['word_count'].mean()),
                "Most Engaging Length": int(self.df.groupby('word_count')['likes'].mean().idxmax()),
                "Media Impact": {
                    "With Media Avg Likes": float(self.df[self.df['has_media']]['likes'].mean()),
                    "Without Media Avg Likes": float(self.df[~self.df['has_media']]['likes'].mean())
                }
            },
            "Author Performance": {
                author: {
                    "Avg Likes": float(group['likes'].mean()),
                    "Avg Reposts": float(group['reposts'].mean()),
                    "Total Posts": int(len(group))
                }
                for author, group in self.df.groupby('author')
            }
        }
        
        with open('analysis_insights.json', 'w') as f:
            json.dump(insights, f, indent=2)
        
        return insights

if __name__ == "__main__":
    analyzer = BlueskyAnalyzer()
    
    # Generate visualizations
    print("Generating engagement analysis...")
    analyzer.generate_engagement_analysis()
    
    print("Generating content analysis...")
    analyzer.analyze_content_patterns()
    
    print("Generating insights report...")
    insights = analyzer.generate_insights_report()
    
    print("\nKey Insights:")
    print(f"Best day to post: {insights['Post Timing']['Best Day']}")
    print(f"Best hour to post: {insights['Post Timing']['Best Hour']}:00")
    print(f"Average word count: {insights['Content Analysis']['Avg Word Count']:.1f} words")
    
    print("\nAnalysis complete! Check the following files:")
    print("1. engagement_analysis.png")
    print("2. content_analysis.png")
    print("3. analysis_insights.json")
