from atproto import Client
import pandas as pd
from datetime import datetime, timedelta
import json
import time

class BlueskyDataCollector:
    def __init__(self):
        self.client = Client()
        self.posts_data = []
        
    def login(self, email, password):
        """Login to Bluesky"""
        profile = self.client.login(email, password)
        print(f"Logged in as {profile.handle}")
        
    def collect_user_data(self, handle, limit=100):
        """
        Collect posts and engagement data for a specific user
        
        Parameters:
        handle (str): User handle (e.g., 'bsky.app')
        limit (int): Maximum number of posts to collect
        """
        try:
            print(f"\nCollecting data for @{handle}...")
            profile = self.client.get_profile(actor=handle)
            
            cursor = None
            posts_collected = 0
            
            while posts_collected < limit:
                # Fetch posts
                response = self.client.get_author_feed(
                    actor=handle,
                    cursor=cursor,
                    limit=min(100, limit - posts_collected)
                )
                
                for post in response.feed:
                    # Extract post data
                    post_data = {
                        'author': handle,
                        'text': post.post.text,
                        'timestamp': post.post.indexed_at,
                        'likes': post.post.like_count,
                        'reposts': post.post.repost_count,
                        'replies': post.post.reply_count,
                        'has_media': bool(post.post.embed),
                        'media_type': self._get_media_type(post.post.embed),
                        'is_reply': bool(post.post.reply),
                        'word_count': len(post.post.text.split()),
                        'character_count': len(post.post.text),
                        'mentions_count': len([f for f in (post.post.facets or []) 
                                            if hasattr(f, 'features') and any(feat.did for feat in f.features)]),
                        'urls_count': len([f for f in (post.post.facets or []) 
                                         if hasattr(f, 'features') and any(feat.uri for feat in f.features)])
                    }
                    
                    # Add time-based features
                    post_time = datetime.fromisoformat(post_data['timestamp'].replace('Z', '+00:00'))
                    post_data['hour_of_day'] = post_time.hour
                    post_data['day_of_week'] = post_time.strftime('%A')
                    post_data['is_weekend'] = post_time.weekday() >= 5
                    
                    self.posts_data.append(post_data)
                    posts_collected += 1
                    
                    # Progress update
                    if posts_collected % 10 == 0:
                        print(f"Collected {posts_collected} posts...")
                
                if not response.cursor or posts_collected >= limit:
                    break
                    
                cursor = response.cursor
                time.sleep(0.5)  # Rate limiting
                
            print(f"Successfully collected {posts_collected} posts for @{handle}")
            
        except Exception as e:
            print(f"Error collecting data for {handle}: {str(e)}")
    
    def _get_media_type(self, embed):
        """Determine the type of media in the post"""
        if not embed:
            return None
        
        embed_type = type(embed).__name__
        if 'Images' in embed_type:
            return 'image'
        elif 'Record' in embed_type:
            return 'quote'
        elif 'External' in embed_type:
            return 'link'
        return 'other'
    
    def save_to_json(self, filename='bluesky_data.json'):
        """Save collected data to JSON file"""
        with open(filename, 'w') as f:
            json.dump(self.posts_data, f, indent=2)
        print(f"\nData saved to {filename}")
    
    def save_to_csv(self, filename='bluesky_data.csv'):
        """Save collected data to CSV file"""
        df = pd.DataFrame(self.posts_data)
        df.to_csv(filename, index=False)
        print(f"\nData saved to {filename}")
    
    def get_basic_stats(self):
        """Calculate and print basic statistics about the collected data"""
        df = pd.DataFrame(self.posts_data)
        
        stats = {
            'Total Posts': len(df),
            'Date Range': f"{df['timestamp'].min()} to {df['timestamp'].max()}",
            'Average Likes': df['likes'].mean(),
            'Average Reposts': df['reposts'].mean(),
            'Average Replies': df['replies'].mean(),
            'Posts with Media': df['has_media'].sum(),
            'Most Active Day': df['day_of_week'].mode().iloc[0],
            'Most Active Hour': df['hour_of_day'].mode().iloc[0]
        }
        
        print("\nBasic Statistics:")
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"{key}: {value:.2f}")
            else:
                print(f"{key}: {value}")

# Example usage
if __name__ == "__main__":
    collector = BlueskyDataCollector()
    
    # Get credentials
    email = input("Enter your Bluesky email: ")
    password = input("Enter your Bluesky password: ")
    
    # Login
    collector.login(email, password)
    
    # Collect data for specific accounts
    accounts = ['bsky.app', 'jay.bsky.team', 'emilyliu.me']
    for account in accounts:
        collector.collect_user_data(account, limit=100)
    
    # Save data
    collector.save_to_json()
    collector.save_to_csv()
    
    # Show basic stats
    collector.get_basic_stats()
