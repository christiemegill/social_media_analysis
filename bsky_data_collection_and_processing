from atproto import Client
import pandas as pd
from datetime import datetime, timedelta
import json
import time

class BlueskyDataCollector:
    def __init__(self):
        self.client = Client()
        self.posts_data = []
        
    def login(self, email, password):
        """Login to Bluesky"""
        profile = self.client.login(email, password)
        print(f"Logged in as {profile.handle}")
        
    def collect_user_data(self, handle, limit=100):
        """Collect posts and engagement data for a specific user"""
        try:
            print(f"\nCollecting data for @{handle}...")
            profile = self.client.get_profile(actor=handle)
            
            cursor = None
            posts_collected = 0
            
            while posts_collected < limit:
                try:
                    # Fetch posts
                    response = self.client.get_author_feed(
                        actor=handle,
                        cursor=cursor,
                        limit=min(100, limit - posts_collected)
                    )
                    
                    for post in response.feed:
                        try:
                            # Extract post data with error handling
                            post_data = {
                                'author': handle,
                                'text': getattr(post.post, 'text', ''),
                                'created_at': getattr(post.post, 'created_at', None),
                                'likes': getattr(post.post, 'like_count', 0),
                                'reposts': getattr(post.post, 'repost_count', 0),
                                'replies': getattr(post.post, 'reply_count', 0),
                                'has_media': bool(getattr(post.post, 'embed', None)),
                                'media_type': self._get_media_type(getattr(post.post, 'embed', None)),
                                'is_reply': bool(getattr(post.post, 'reply', None)),
                                'word_count': len(getattr(post.post, 'text', '').split()),
                                'character_count': len(getattr(post.post, 'text', '')),
                            }
                            
                            # Add time-based features
                            if post_data['created_at']:
                                post_time = datetime.fromisoformat(post_data['created_at'].replace('Z', '+00:00'))
                                post_data['hour_of_day'] = post_time.hour
                                post_data['day_of_week'] = post_time.strftime('%A')
                                post_data['is_weekend'] = post_time.weekday() >= 5
                            
                            self.posts_data.append(post_data)
                            posts_collected += 1
                            
                        except Exception as e:
                            print(f"Error processing post: {str(e)}")
                            continue
                    
                    if not response.cursor or posts_collected >= limit:
                        break
                        
                    cursor = response.cursor
                    time.sleep(0.5)  # Rate limiting
                    
                except Exception as e:
                    print(f"Error fetching page: {str(e)}")
                    break
                    
            print(f"Successfully collected {posts_collected} posts for @{handle}")
            
        except Exception as e:
            print(f"Error collecting data for {handle}: {str(e)}")
    
    def _get_media_type(self, embed):
        """Determine the type of media in the post"""
        if not embed:
            return None
        
        try:
            embed_type = getattr(embed, '$type', None)
            if not embed_type and hasattr(embed, 'type'):
                embed_type = embed.type
                
            if 'video' in str(embed_type).lower():
                return 'video'
            elif 'image' in str(embed_type).lower():
                return 'image'
            elif 'record' in str(embed_type).lower():
                return 'quote'
            elif 'external' in str(embed_type).lower():
                return 'link'
            return 'other'
            
        except Exception:
            return 'unknown'
    
    def save_to_json(self, filename='bluesky_data.json'):
        """Save collected data to JSON file"""
        with open(filename, 'w') as f:
            json.dump(self.posts_data, f, indent=2)
        print(f"\nData saved to {filename}")
    
    def save_to_csv(self, filename='bluesky_data.csv'):
        """Save collected data to CSV file"""
        df = pd.DataFrame(self.posts_data)
        df.to_csv(filename, index=False)
        print(f"\nData saved to {filename}")
    
    def get_basic_stats(self):
        """Calculate and print basic statistics about the collected data"""
        if not self.posts_data:
            print("No data collected yet!")
            return
            
        df = pd.DataFrame(self.posts_data)
        
        stats = {
            'Total Posts': len(df),
            'Date Range': f"{df['created_at'].min()} to {df['created_at'].max()}" if 'created_at' in df.columns else "N/A",
            'Average Likes': df['likes'].mean(),
            'Average Reposts': df['reposts'].mean(),
            'Average Replies': df['replies'].mean(),
            'Posts with Media': df['has_media'].sum(),
            'Most Common Media Type': df['media_type'].mode().iloc[0] if not df['media_type'].isna().all() else "None",
            'Most Active Day': df['day_of_week'].mode().iloc[0] if 'day_of_week' in df.columns else "N/A",
            'Most Active Hour': df['hour_of_day'].mode().iloc[0] if 'hour_of_day' in df.columns else "N/A"
        }
        
        print("\nBasic Statistics:")
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"{key}: {value:.2f}")
            else:
                print(f"{key}: {value}")

if __name__ == "__main__":
    collector = BlueskyDataCollector()
    
    # Get credentials
    email = input("Enter your Bluesky email: ")
    password = input("Enter your Bluesky password: ")
    
    # Login
    collector.login(email, password)
    
    # Collect data for specific accounts
    accounts = ['bsky.app', 'jay.bsky.team', 'emilyliu.me']
    for account in accounts:
        collector.collect_user_data(account, limit=100)
    
    # Save data
    collector.save_to_json()
    collector.save_to_csv()
    
    # Show basic stats
    collector.get_basic_stats()
